{"cells":[{"cell_type":"code","source":["!pip install --upgrade pyarrow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxPYgMEB22L9","executionInfo":{"status":"ok","timestamp":1720707190574,"user_tz":-120,"elapsed":37478,"user":{"displayName":"basura correo","userId":"13953499630049004495"}},"outputId":"8bd412b9-9f7d-4341-b088-6e73d87c5516"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n","Collecting pyarrow\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n","Installing collected packages: pyarrow\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pyarrow-16.1.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xxbHY-I385MR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720707333379,"user_tz":-120,"elapsed":142810,"user":{"displayName":"basura correo","userId":"13953499630049004495"}},"outputId":"f45060d9-8b6d-451b-a3e4-e9f213414e98"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.32.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["#Descargamos la libreria de transformers que usaremos para descargar el modelo como su respectivo tokenizador\n","!pip  install transformers --quiet\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","from transformers import Trainer\n","!pip install Datasets --quiet\n","from datasets import DatasetDict, Dataset\n","!pip install transformers[torch] --quiet\n","!pip install accelerate -U --quiet\n","!pip install transformers[torch]\n","#Installamos esta librería para el preprocesamiento necesario que requieré el modelo RoBertTuito:\n","!pip install pysentimiento --quiet\n","from pysentimiento.preprocessing import preprocess_tweet"]},{"cell_type":"code","source":[],"metadata":{"id":"s1cCVDD_18-2","executionInfo":{"status":"ok","timestamp":1720707333379,"user_tz":-120,"elapsed":3,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"n1tz9n9i9J4W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720707334418,"user_tz":-120,"elapsed":1041,"user":{"displayName":"basura correo","userId":"13953499630049004495"}},"outputId":"4a1179a7-7a1c-45d9-fed0-65c5411dcd9a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}],"source":["# Importamos las dependencias necesarias :\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('omw-1.4')\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from google.colab import drive  #Montador de drive\n","from sklearn.model_selection import train_test_split\n","import gc"]},{"cell_type":"markdown","metadata":{"id":"dvQFEqkc9MP9"},"source":["# 2. Importamos el conjunto de datos que vamos a usar para nuestro problema"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"hGIQIrYd9SDd","colab":{"base_uri":"https://localhost:8080/","height":316},"executionInfo":{"status":"error","timestamp":1720707456072,"user_tz":-120,"elapsed":121658,"user":{"displayName":"basura correo","userId":"13953499630049004495"}},"outputId":"13497d51-105c-4903-b0b1-7478680e065c"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7c016dd09720>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Datasets a limpio /EXIST 2021 dataset_esp.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["drive.mount('/content/drive')\n","df = pd.read_csv('/content/drive/MyDrive/Datasets a limpio /EXIST 2021 dataset_esp.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hD0i6hdm9kKM","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":6,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-cH-ra89g8O","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["# 1. Cambiamos el nombre de las columnas e eliminamos aquellas que no necesitamos:\n","columns_to_remove = ['test_case', 'id', 'source','language','task2']\n","df = df.rename(columns = {\"task1\": \"label\"}).drop(columns=columns_to_remove, axis=1)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKaWPQ949phk","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["# 2. Cambiamos los valores nominales de nuestra etiqueta por valores númericos\n","df['label'] = df['label'].replace(['non-sexist','sexist'],[0, 1])\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaD6rz8k-AWN","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["# 3. Eliminamos cualquier fila que haya podido quedar en blanco:\n","df = df.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Janb9VfG-M0s","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["from pysentimiento.preprocessing import preprocess_tweet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9dwzcDq-xzt","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["df['text'].apply(preprocess_tweet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gn3SAkm-8_f","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dz6LrN83_W1c","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["# 4. Dividiremos el dataset en el 80% para el entrenamiento, el 10% para el proceso de validation, y un 10% para testear los resultados del modelo.\n","train_df, valtest_df = train_test_split(df, test_size = 0.2, random_state = 42)\n","val_df, test_df = train_test_split(valtest_df, test_size = 0.5, random_state = 42)\n","train_df.shape, val_df.shape, test_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvO8I1Ui_Z61","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["train = Dataset.from_pandas(train_df)\n","validation = Dataset.from_pandas(val_df)\n","test = Dataset.from_pandas(test_df)"]},{"cell_type":"code","source":["train"],"metadata":{"id":"4rkBVh0U0zC2","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ursObwjc_QGW"},"source":["\n","\n","```\n","# Funciones para entrenar el modelo\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yJ0ts-RJ1Y8","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["# Define a function to train a model v2\n","class TrainModel:\n","    \"\"\"\n","\n","    Attributes:\n","      tokenizer:\n","      modelo:\n","    \"\"\"\n","\n","    def __init__(self, Modelo):\n","        # Check if execution will be performed on cuda:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.tokenizer = AutoTokenizer.from_pretrained(Modelo)\n","        self.modelo = AutoModelForSequenceClassification.from_pretrained(Modelo, num_labels=2).to(device)\n","\n","    def tokenizador(self, batch):\n","        return self.tokenizer(batch[\"text\"], padding=True, max_length=128, truncation=True)\n","\n","    def compute_metrics(self, pred):\n","        labels = pred.label_ids\n","        preds = pred.predictions.argmax(-1)\n","        f1 = f1_score(labels, preds, average=\"weighted\")\n","        acc = accuracy_score(labels, preds)\n","        return {\"accuracy\": acc, \"f1\": f1}\n","\n","    def train(self, train, val):\n","        # Prepare the dataset:\n","        Tweets_Dataset = DatasetDict({'train': train, 'val': val, 'test': test})\n","\n","        # Apply tokenization to the entire dataset using the map function:\n","        #Tweets_Dataset = Tweets_Dataset.remove_columns([\"__index_level_0__\"])\n","        Tweets_Encoded = Tweets_Dataset.map(self.tokenizador, batched=True, batch_size=None)\n","\n","\n","        # Ensure objects are of torch type\n","        Tweets_Encoded.set_format(\"torch\", columns=[\"label\", \"input_ids\", \"attention_mask\"])\n","\n","        # Definimos los hiperparametros de cada modelo\n","        if self.modelo == 'sdadas/xlm-roberta-large-twitter':\n","            learning_rate = 2e-5\n","            per_device_train_batch_size = 16\n","            num_train_epochs=2\n","        elif self.modelo == 'Twitter/twhin-bert-base':\n","            learning_rate = 2e-5\n","            per_device_train_batch_size = 16\n","            num_train_epochs=4\n","        else:\n","            learning_rate = 1e-5\n","            per_device_train_batch_size = 16\n","            num_train_epochs=3\n","\n","        training_args = TrainingArguments(\n","              output_dir='./results',\n","              num_train_epochs= num_train_epochs,\n","              learning_rate = learning_rate,\n","              per_device_train_batch_size= per_device_train_batch_size,\n","              per_device_eval_batch_size=8,\n","              warmup_steps=500,\n","              weight_decay=0.01,\n","              evaluation_strategy=\"epoch\",\n","              logging_dir='./logs',\n","              )\n","\n","        # Create the Trainer and train the model\n","        trainer = Trainer(\n","            model=self.modelo,\n","            args=training_args,\n","            compute_metrics=self.compute_metrics,\n","            train_dataset=Tweets_Encoded['train'],\n","            eval_dataset=Tweets_Encoded['val'],\n","        )\n","        trainer.train()\n","\n","        return self.modelo, self.tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTRFdV_sHjfS","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["train = train.remove_columns([\"__index_level_0__\"])\n","validation = validation.remove_columns([\"__index_level_0__\"])\n","test = test.remove_columns([\"__index_level_0__\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfruBsYhGnkT","executionInfo":{"status":"aborted","timestamp":1720707456073,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["train = Dataset.from_pandas(train_df)\n","validation = Dataset.from_pandas(val_df)\n","test = Dataset.from_pandas(test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYrmCmNVGNOT","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["sdadas_trainer = TrainModel('sdadas/xlm-roberta-large-twitter')\n","twhin_trainer = TrainModel('Twitter/twhin-bert-base')\n","robertuito_trainer = TrainModel('pysentimiento/robertuito-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Tz80TUbpyli","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["Modelo1, tokenizador1 = sdadas_trainer.train(train, validation)\n","Modelo2, tokenizador2 = twhin_trainer.train(train, validation)\n","Modelo3, tokenizador3 = robertuito_trainer.train(train, validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G03xdUJbLBrF","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":5,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["modelos = [Modelo1,Modelo2,Modelo3]\n","tokenizadores = [tokenizador1,tokenizador2,tokenizador3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1qUfcNGtq9u","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["https://www.kaggle.com/code/emiz6413/transformers-united-majority-voting/notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzC_Tuj1LAwb","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["def majority_voting(models, tokenizers, texts):\n","    # Initialize a list to store the majority vote for each text\n","    majority_votes = []\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    for text in texts:\n","        # Get the predictions from each model\n","        predictions = []\n","        for model, tokenizer in zip(models, tokenizers):\n","            inputs = tokenizer(text, return_tensors='pt', padding=True, max_length=128, truncation=True)\n","            inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n","\n","            with torch.no_grad():\n","                model_logits = model(**inputs).logits\n","                _, preds = torch.max(model_logits, dim=1)\n","                predictions.append(preds)\n","\n","        # majority voting\n","        predictions = torch.stack(predictions).to(device)\n","        majority_vote, _ = torch.mode(predictions, dim=0)\n","\n","        # Append the majority vote to the list\n","        majority_votes.append(majority_vote.item())\n","\n","    return majority_votes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLozpwv_LXCv","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["predictions = majority_voting(modelos, tokenizadores, validation['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJjHlhomLjB1","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["def compute_metrics(true_labels, predictions):\n","    # Compute the accuracy\n","    accuracy = accuracy_score(true_labels, predictions)\n","\n","    # Compute the F1 score\n","    f1 = f1_score(true_labels, predictions, average='weighted')\n","\n","    return accuracy, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3tpSGHimLxZp","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["accuracy , f1 = compute_metrics(validation['label'],predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NP_LDrCQv9Y","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KOs93teXQyh4","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":["f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75hL4Qz7RYd5","executionInfo":{"status":"aborted","timestamp":1720707456074,"user_tz":-120,"elapsed":4,"user":{"displayName":"basura correo","userId":"13953499630049004495"}}},"outputs":[],"source":[" Define a function to train a model v2\n","class TrainModel:\n","    \"\"\"\n","\n","    Attributes:\n","      tokenizer:\n","      modelo:\n","    \"\"\"\n","\n","    def __init__(self, Modelo):\n","        # Check if execution will be performed on cuda:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.tokenizer = AutoTokenizer.from_pretrained(Modelo)\n","        self.modelo = AutoModelForSequenceClassification.from_pretrained(Modelo, num_labels=2).to(device)\n","\n","    def tokenizador(self, batch):\n","        return self.tokenizer(batch[\"text\"], padding=True, max_length=128, truncation=True)\n","\n","    def compute_metrics(self, pred):\n","        labels = pred.label_ids\n","        preds = pred.predictions.argmax(-1)\n","        f1 = f1_score(labels, preds, average=\"weighted\")\n","        acc = accuracy_score(labels, preds)\n","        return {\"accuracy\": acc, \"f1\": f1}\n","\n","    def train(self, train, val):\n","        # Prepare the dataset:\n","        Tweets_Dataset = DatasetDict({'train': train, 'val': val, 'test': test})\n","\n","        # Apply tokenization to the entire dataset using the map function:\n","        Tweets_Dataset = Tweets_Dataset.remove_columns([\"__index_level_0__\"])\n","        Tweets_Encoded = Tweets_Dataset.map(self.tokenizador, batched=True, batch_size=None)\n","\n","        # Ensure objects are of torch type\n","        Tweets_Encoded.set_format(\"torch\", columns=[\"label\", \"input_ids\", \"attention_mask\"])\n","\n","        training_args = TrainingArguments(\n","            output_dir='./results',\n","            num_train_epochs=2,\n","            learning_rate = 2e-5,\n","            per_device_train_batch_size=16,\n","            per_device_eval_batch_size=16,\n","            warmup_steps=500,\n","            weight_decay=0.01,\n","            evaluation_strategy=\"epoch\",\n","            logging_dir='./logs',\n","        )\n","\n","        # Create the Trainer and train the model\n","        trainer = Trainer(\n","            model=self.modelo,\n","            args=training_args,\n","            compute_metrics=self.compute_metrics,\n","            train_dataset=Tweets_Encoded['train'],\n","            eval_dataset=Tweets_Encoded['val'],\n","        )\n","        trainer.train()\n","\n","        return self.modelo, self.tokenizer"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1p7I2G2A9FySiRgB3pbfVLao6VHArNAcu","timestamp":1715783092615}],"authorship_tag":"ABX9TyN1A620M84igqQK6c+OD0zY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}